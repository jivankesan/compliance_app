from langchain_experimental.text_splitter import SemanticChunker
from langchain.text_splitter import RecursiveCharacterTextSplitter

class TextProcessor:
    """
    Handles splitting of text into chunks.
    """
    def __init__(self, embedding_model, threshold_type="percentile", threshold_amount=88.0):
        self.text_splitter = SemanticChunker(
            embedding_model,
            breakpoint_threshold_type=threshold_type,
            breakpoint_threshold_amount=threshold_amount
        )

    def create_chunks(self, text: str):
        """
        Creates chunks from text using the SemanticChunker.
        Returns a list of Document objects (LangChain style).
        """
        docs = self.text_splitter.create_documents([text])
        return docs
